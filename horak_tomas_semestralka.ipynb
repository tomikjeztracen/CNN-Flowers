{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomikjeztracen/CNN-Flowers/blob/main/horak_tomas_semestralka.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/resized.zip'\n",
        "# Directory where you want to extract the files\n",
        "extract_dir = './prod'\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Files extracted to {extract_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5-SNO9spPab",
        "outputId": "12cbd733-bce3-48ab-8e1a-e780c5f27664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to ./prod\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths\n",
        "image_folder = '/content/data/images'  # Path to the folder containing images\n",
        "csv_file = '/content/one_hot_encoded_flowers.csv'   # Path to the CSV with one-hot encoded labels\n",
        "\n",
        "# Load the CSV with image labels\n",
        "labels_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Prepare image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Loop through the CSV and load corresponding images and labels\n",
        "for i, row in labels_df.iterrows():\n",
        "    image_filename = row['filename']  # Assuming the column containing filenames is named 'image_filename'\n",
        "    label = row.drop('filename').values  # Drop 'image_filename' and keep the one-hot encoded label\n",
        "    image_path = os.path.join(image_folder, image_filename)\n",
        "\n",
        "    # Read the image (images are already 128px)\n",
        "    try:\n",
        "      img = load_img(image_path, target_size=(128, 128))  # Ensure size (128, 128)\n",
        "    except:\n",
        "      print(\"skipped\")\n",
        "    img_array = img_to_array(img)  # Convert image to numpy array\n",
        "\n",
        "    image_paths.append(img_array)\n",
        "    labels.append(label)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(image_paths)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Validation data shape: {X_val.shape}\")\n",
        "\n",
        "\n",
        "https://www.youtube.com/watch?v=q7ZuZ8ZOErE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "4k0C3GXSp7o5",
        "outputId": "50ad0dcd-ba73-4379-82a3-035507fc58d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/one_hot_encoded_flowers.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6f22c5d5fc85>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load the CSV with image labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlabels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Prepare image paths and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/one_hot_encoded_flowers.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "directory = \"/content/data/resized\"\n",
        "\n",
        "df = pd.read_csv(\"/content/encoded.csv\")\n",
        "\n",
        "file_paths = df[\"filename\"].values\n",
        "labels = df[\"numerical_label\"].values\n",
        "\n",
        "tf_dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "def read_image(image_file, label):\n",
        "    image = tf.io.read_file(directory + image_file)\n",
        "    image = tf.image.decode_image(image, channels=3, dtype=tf.float32)\n",
        "    return image,label\n",
        "\n",
        "tf_dataset_output = tf_dataset.map(read_image).batch(32)\n",
        "print(tf_dataset_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDz_Ag7D53cd",
        "outputId": "2fa6ab66-fbdf-4af3-ea33-d2b381864016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Directory and CSV loading\n",
        "directory = \"/content/prod/resized\"\n",
        "df = pd.read_csv(\"/content/encoded.csv\")\n",
        "\n",
        "# File paths and labels\n",
        "file_paths = df[\"filename\"].values\n",
        "labels = df[\"numerical_label\"].values\n",
        "\n",
        "# TensorFlow dataset\n",
        "tf_dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "# Function to read and decode images\n",
        "def read_image(image_file, label):\n",
        "    image = tf.io.read_file(directory + \"/\" + image_file)  # Read the image file\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Decode the image as RGB\n",
        "    image = tf.image.resize(image, [128, 128])  # Resize image to 128x128\n",
        "    image = tf.cast(image, tf.float32)  # Cast the image to float32\n",
        "    image /= 255.0  # Normalize the image to [0, 1] range\n",
        "    return image, label\n",
        "\n",
        "# Map the read_image function and batch the data\n",
        "tf_dataset_output = tf_dataset.map(read_image).shuffle(1000).batch(128)\n",
        "\n",
        "# Define a simple Keras model\n",
        "model = Sequential([\n",
        "    Input(shape=(128, 128, 3)),  # Input shape\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),  # Dropout to prevent overfitting\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(25, activation='softmax')  # 25 classes\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(tf_dataset_output, epochs=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELkFcuun8C0n",
        "outputId": "872a0627-c404-4435-b61e-4582e4a81c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 142ms/step - accuracy: 0.2854 - loss: 5.4953\n",
            "Epoch 2/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 0.0368 - loss: 3.1909\n",
            "Epoch 3/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.0905 - loss: 3.1972\n",
            "Epoch 4/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - accuracy: 0.1244 - loss: 3.1693\n",
            "Epoch 5/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.1361 - loss: 3.1802\n",
            "Epoch 6/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 79ms/step - accuracy: 0.1206 - loss: 3.2069\n",
            "Epoch 7/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.1216 - loss: 3.1989\n",
            "Epoch 8/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.1288 - loss: 3.1866\n",
            "Epoch 9/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.1224 - loss: 3.1955\n",
            "Epoch 10/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.1230 - loss: 3.1916\n",
            "Epoch 11/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.1216 - loss: 3.1892\n",
            "Epoch 12/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.1220 - loss: 3.1872\n",
            "Epoch 13/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.1219 - loss: 3.1855\n",
            "Epoch 14/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.1271 - loss: 3.1805\n",
            "Epoch 15/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.1184 - loss: 3.1946\n",
            "Epoch 16/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.1215 - loss: 3.1797\n",
            "Epoch 17/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.1227 - loss: 3.1782\n",
            "Epoch 18/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.1220 - loss: 3.1756\n",
            "Epoch 19/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.1225 - loss: 3.1743\n",
            "Epoch 20/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.1221 - loss: 3.1728\n",
            "Epoch 21/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.1212 - loss: 3.1714\n",
            "Epoch 22/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.1224 - loss: 3.1695\n",
            "Epoch 23/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.1224 - loss: 3.1696\n",
            "Epoch 24/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.1226 - loss: 3.1689\n",
            "Epoch 25/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.1225 - loss: 3.1682\n",
            "Epoch 26/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.1235 - loss: 3.1671\n",
            "Epoch 27/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.1224 - loss: 3.1669\n",
            "Epoch 28/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.1233 - loss: 3.1655\n",
            "Epoch 29/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.1222 - loss: 3.1655\n",
            "Epoch 30/30\n",
            "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.1227 - loss: 3.1643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78e616062bf0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Directory and CSV loading\n",
        "directory = \"/content/prod/resized\"\n",
        "df = pd.read_csv(\"/content/encoded.csv\")\n",
        "\n",
        "# File paths and labels\n",
        "file_paths = df[\"filename\"].values\n",
        "labels = df[\"numerical_label\"].values\n",
        "\n",
        "# TensorFlow dataset\n",
        "tf_dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "# Function to read and decode images\n",
        "def read_image(image_file, label):\n",
        "    image = tf.io.read_file(directory + \"/\" + image_file)  # Read the image file\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Decode the image as RGB\n",
        "    image = tf.image.resize(image, [128, 128])  # Resize image to 128x128\n",
        "    image = tf.cast(image, tf.float32)  # Cast the image to float32\n",
        "    image /= 255.0  # Normalize the image to [0, 1] range\n",
        "    return image, label\n",
        "\n",
        "# Map the read_image function and batch the data\n",
        "tf_dataset_output = tf_dataset.map(read_image).shuffle(1000).batch(32)\n",
        "\n",
        "# Data Augmentation with ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Define a more complex Keras model with better initialization, dropout, and batch normalization\n",
        "model = Sequential([\n",
        "    layers.Input(shape=(128, 128, 3)),  # Input shape\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu', kernel_initializer='he_normal'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu', kernel_initializer='he_normal'),\n",
        "    Dropout(0.5),\n",
        "    Dense(25, activation='softmax')  # 25 classes\n",
        "])\n",
        "\n",
        "# Create an Adam optimizer with a learning rate\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Calculate class weights based on label distribution (if needed)\n",
        "class_weights = dict(zip(*np.unique(labels, return_counts=True)))\n",
        "total = len(labels)\n",
        "class_weights = {k: total / v for k, v in class_weights.items()}\n",
        "\n",
        "# Early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with class weights and early stopping\n",
        "model.fit(tf_dataset_output, epochs=200, class_weight=class_weights, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP3Aq2lNEfSj",
        "outputId": "d12c82aa-b2f8-4a9e-9584-21074f4fc377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.2924 - loss: 81.9408\n",
            "Epoch 2/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.1371 - loss: 73.0537\n",
            "Epoch 3/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.1420 - loss: 72.2377\n",
            "Epoch 4/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.1112 - loss: 73.8323\n",
            "Epoch 5/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.1426 - loss: 71.8099\n",
            "Epoch 6/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.1426 - loss: 72.1266\n",
            "Epoch 7/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.1301 - loss: 72.4403\n",
            "Epoch 8/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.1004 - loss: 72.5625\n",
            "Epoch 9/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.1138 - loss: 72.0803\n",
            "Epoch 10/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.1258 - loss: 71.5750\n",
            "Epoch 11/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.0880 - loss: 73.5240\n",
            "Epoch 12/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.1253 - loss: 70.5962\n",
            "Epoch 13/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.1233 - loss: 70.5906\n",
            "Epoch 14/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.1157 - loss: 71.2577\n",
            "Epoch 15/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.1121 - loss: 73.2136\n",
            "Epoch 16/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.1154 - loss: 71.6946\n",
            "Epoch 17/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.1295 - loss: 71.1146\n",
            "Epoch 18/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.1397 - loss: 71.5994\n",
            "Epoch 19/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.1604 - loss: 70.1714\n",
            "Epoch 20/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.1972 - loss: 69.7726\n",
            "Epoch 21/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.2088 - loss: 68.4593\n",
            "Epoch 22/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.2596 - loss: 65.0283\n",
            "Epoch 23/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.3043 - loss: 60.3508\n",
            "Epoch 24/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.3404 - loss: 57.2491\n",
            "Epoch 25/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.3758 - loss: 52.5969\n",
            "Epoch 26/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.4135 - loss: 48.6302\n",
            "Epoch 27/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.4375 - loss: 46.1010\n",
            "Epoch 28/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.4699 - loss: 43.5625\n",
            "Epoch 29/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.5002 - loss: 41.3719\n",
            "Epoch 30/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.5248 - loss: 37.9877\n",
            "Epoch 31/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.5445 - loss: 36.3582\n",
            "Epoch 32/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.5756 - loss: 33.4408\n",
            "Epoch 33/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.6036 - loss: 31.6076\n",
            "Epoch 34/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.6390 - loss: 28.4900\n",
            "Epoch 35/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.6588 - loss: 26.9381\n",
            "Epoch 36/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.6731 - loss: 25.5641\n",
            "Epoch 37/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.7070 - loss: 23.5132\n",
            "Epoch 38/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.7231 - loss: 21.4244\n",
            "Epoch 39/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.7526 - loss: 19.5761\n",
            "Epoch 40/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.7624 - loss: 18.8326\n",
            "Epoch 41/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.7752 - loss: 17.2259\n",
            "Epoch 42/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.7830 - loss: 16.5317\n",
            "Epoch 43/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.8068 - loss: 15.0216\n",
            "Epoch 44/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.8175 - loss: 14.0768\n",
            "Epoch 45/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.8221 - loss: 13.9796\n",
            "Epoch 46/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8397 - loss: 12.7796\n",
            "Epoch 47/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.8377 - loss: 12.9809\n",
            "Epoch 48/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8479 - loss: 12.5014\n",
            "Epoch 49/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.8555 - loss: 11.5745\n",
            "Epoch 50/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.8651 - loss: 10.5826\n",
            "Epoch 51/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8782 - loss: 9.3674\n",
            "Epoch 52/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.8858 - loss: 8.8711\n",
            "Epoch 53/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.8810 - loss: 9.6960\n",
            "Epoch 54/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8851 - loss: 9.0331\n",
            "Epoch 55/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8883 - loss: 9.3628\n",
            "Epoch 56/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.8944 - loss: 8.1672\n",
            "Epoch 57/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9022 - loss: 8.0532\n",
            "Epoch 58/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9033 - loss: 7.6308\n",
            "Epoch 59/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9084 - loss: 7.2973\n",
            "Epoch 60/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9098 - loss: 7.0892\n",
            "Epoch 61/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.9139 - loss: 6.5769\n",
            "Epoch 62/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9181 - loss: 6.5928\n",
            "Epoch 63/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9239 - loss: 6.1853\n",
            "Epoch 64/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9198 - loss: 6.2126\n",
            "Epoch 65/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9298 - loss: 5.7123\n",
            "Epoch 66/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9199 - loss: 6.4534\n",
            "Epoch 67/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.9191 - loss: 6.4894\n",
            "Epoch 68/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9269 - loss: 5.7335\n",
            "Epoch 69/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9226 - loss: 6.5177\n",
            "Epoch 70/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9237 - loss: 6.1130\n",
            "Epoch 71/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9259 - loss: 5.6804\n",
            "Epoch 72/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.9323 - loss: 6.0283\n",
            "Epoch 73/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9266 - loss: 5.8306\n",
            "Epoch 74/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9295 - loss: 5.8263\n",
            "Epoch 75/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9353 - loss: 5.3569\n",
            "Epoch 76/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.9372 - loss: 5.2056\n",
            "Epoch 77/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9401 - loss: 4.7469\n",
            "Epoch 78/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9374 - loss: 5.0870\n",
            "Epoch 79/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9376 - loss: 4.7493\n",
            "Epoch 80/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9386 - loss: 5.0377\n",
            "Epoch 81/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9379 - loss: 5.0001\n",
            "Epoch 82/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9435 - loss: 4.7656\n",
            "Epoch 83/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9442 - loss: 4.7265\n",
            "Epoch 84/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9466 - loss: 4.6695\n",
            "Epoch 85/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9474 - loss: 4.0992\n",
            "Epoch 86/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9440 - loss: 4.4376\n",
            "Epoch 87/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.9441 - loss: 4.5757\n",
            "Epoch 88/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9483 - loss: 4.1064\n",
            "Epoch 89/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9464 - loss: 4.2619\n",
            "Epoch 90/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9511 - loss: 3.7292\n",
            "Epoch 91/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9537 - loss: 3.5412\n",
            "Epoch 92/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9501 - loss: 4.3141\n",
            "Epoch 93/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9494 - loss: 4.1563\n",
            "Epoch 94/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9480 - loss: 4.4936\n",
            "Epoch 95/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9532 - loss: 3.6718\n",
            "Epoch 96/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9545 - loss: 3.7301\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78e70d8e1330>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Directory and CSV loading\n",
        "directory = \"/content/prod/resized\"\n",
        "df = pd.read_csv(\"/content/encoded.csv\")\n",
        "\n",
        "# File paths and labels\n",
        "file_paths = df[\"filename\"].values\n",
        "labels = df[\"numerical_label\"].values\n",
        "\n",
        "# Split the dataset into train and validation sets (80/20 split)\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(file_paths, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# TensorFlow datasets for train and validation sets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
        "\n",
        "# Function to read and decode images\n",
        "def read_image(image_file, label):\n",
        "    image = tf.io.read_file(directory + \"/\" + image_file)  # Read the image file\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Decode the image as RGB\n",
        "    image = tf.image.resize(image, [128, 128])  # Resize image to 128x128\n",
        "    image = tf.cast(image, tf.float32)  # Cast the image to float32\n",
        "    image /= 255.0  # Normalize the image to [0, 1] range\n",
        "    return image, label\n",
        "\n",
        "# Map the read_image function and batch the data for train and validation sets\n",
        "train_dataset = train_dataset.map(read_image).shuffle(1000).batch(32)\n",
        "val_dataset = val_dataset.map(read_image).batch(32)\n",
        "\n",
        "# Data Augmentation with ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Define a more complex Keras model with better initialization, dropout, and batch normalization\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(128, 128, 3)),  # Input shape\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(25, activation='softmax')  # 25 classes\n",
        "])\n",
        "# Create an Adam optimizer with a learning rate\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Calculate class weights based on label distribution (if needed)\n",
        "class_weights = dict(zip(*np.unique(labels, return_counts=True)))\n",
        "total = len(labels)\n",
        "class_weights = {k: total / v for k, v in class_weights.items()}\n",
        "\n",
        "# Early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with class weights and early stopping\n",
        "model.fit(tf_dataset_output, epochs=200, class_weight=class_weights, callbacks=[early_stopping],validation_data=val_dataset)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mOfLSDOMqr2",
        "outputId": "6dabda02-0b04-4310-8888-84b9be006f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 34ms/step - accuracy: 0.2939 - loss: 74.4654 - val_accuracy: 0.0905 - val_loss: 3.1639\n",
            "Epoch 2/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.1533 - loss: 70.1692 - val_accuracy: 0.0633 - val_loss: 3.2086\n",
            "Epoch 3/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.1255 - loss: 72.2365 - val_accuracy: 0.0670 - val_loss: 3.2070\n",
            "Epoch 4/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.1399 - loss: 72.5281 - val_accuracy: 0.0697 - val_loss: 3.2051\n",
            "Epoch 5/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.1468 - loss: 71.5254 - val_accuracy: 0.0700 - val_loss: 3.2019\n",
            "Epoch 6/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.1556 - loss: 70.4716 - val_accuracy: 0.0734 - val_loss: 3.1938\n",
            "Epoch 7/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.1745 - loss: 69.0878 - val_accuracy: 0.0855 - val_loss: 3.1705\n",
            "Epoch 8/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.1395 - loss: 71.1532 - val_accuracy: 0.0650 - val_loss: 3.1669\n",
            "Epoch 9/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.1443 - loss: 70.7406 - val_accuracy: 0.0885 - val_loss: 3.1441\n",
            "Epoch 10/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.1456 - loss: 70.3980 - val_accuracy: 0.0848 - val_loss: 3.1455\n",
            "Epoch 11/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.1404 - loss: 70.4238 - val_accuracy: 0.0751 - val_loss: 3.1629\n",
            "Epoch 12/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.1343 - loss: 70.3702 - val_accuracy: 0.0888 - val_loss: 3.1329\n",
            "Epoch 13/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.1732 - loss: 68.8981 - val_accuracy: 0.0905 - val_loss: 3.1350\n",
            "Epoch 14/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.1664 - loss: 68.3779 - val_accuracy: 0.1103 - val_loss: 3.1031\n",
            "Epoch 15/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.1767 - loss: 67.5396 - val_accuracy: 0.1284 - val_loss: 3.0781\n",
            "Epoch 16/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.1513 - loss: 68.5359 - val_accuracy: 0.1129 - val_loss: 3.2031\n",
            "Epoch 17/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.1657 - loss: 67.8495 - val_accuracy: 0.0958 - val_loss: 3.4238\n",
            "Epoch 18/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.1784 - loss: 67.9184 - val_accuracy: 0.1521 - val_loss: 3.2691\n",
            "Epoch 19/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.1930 - loss: 66.9330 - val_accuracy: 0.1009 - val_loss: 3.4931\n",
            "Epoch 20/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.2067 - loss: 65.4232 - val_accuracy: 0.1139 - val_loss: 4.0265\n",
            "Epoch 21/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.2171 - loss: 66.0349 - val_accuracy: 0.1049 - val_loss: 4.0094\n",
            "Epoch 22/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.2298 - loss: 63.0839 - val_accuracy: 0.1133 - val_loss: 4.2375\n",
            "Epoch 23/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.2403 - loss: 63.0347 - val_accuracy: 0.1109 - val_loss: 4.4126\n",
            "Epoch 24/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 31ms/step - accuracy: 0.2751 - loss: 60.0538 - val_accuracy: 0.1330 - val_loss: 3.9569\n",
            "Epoch 25/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.2911 - loss: 57.4391 - val_accuracy: 0.1260 - val_loss: 4.4764\n",
            "Epoch 26/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - accuracy: 0.3137 - loss: 56.4408 - val_accuracy: 0.1277 - val_loss: 4.5876\n",
            "Epoch 27/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.3463 - loss: 53.7841 - val_accuracy: 0.1501 - val_loss: 4.6513\n",
            "Epoch 28/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.3784 - loss: 51.3181 - val_accuracy: 0.1548 - val_loss: 5.2990\n",
            "Epoch 29/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.4114 - loss: 48.4106 - val_accuracy: 0.1960 - val_loss: 4.3174\n",
            "Epoch 30/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.4381 - loss: 45.5033 - val_accuracy: 0.2024 - val_loss: 4.5590\n",
            "Epoch 31/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.4803 - loss: 43.3022 - val_accuracy: 0.2336 - val_loss: 4.2750\n",
            "Epoch 32/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.5047 - loss: 40.8672 - val_accuracy: 0.2306 - val_loss: 4.5941\n",
            "Epoch 33/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 27ms/step - accuracy: 0.5230 - loss: 38.6614 - val_accuracy: 0.2205 - val_loss: 4.5059\n",
            "Epoch 34/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.5535 - loss: 35.8932 - val_accuracy: 0.2798 - val_loss: 3.6462\n",
            "Epoch 35/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.5740 - loss: 34.2054 - val_accuracy: 0.2765 - val_loss: 4.0945\n",
            "Epoch 36/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.5904 - loss: 33.4333 - val_accuracy: 0.2962 - val_loss: 4.3206\n",
            "Epoch 37/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.6201 - loss: 30.1781 - val_accuracy: 0.3097 - val_loss: 3.9654\n",
            "Epoch 38/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.6372 - loss: 29.3513 - val_accuracy: 0.3385 - val_loss: 3.6531\n",
            "Epoch 39/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.6522 - loss: 27.4081 - val_accuracy: 0.3462 - val_loss: 3.9504\n",
            "Epoch 40/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.6692 - loss: 26.4707 - val_accuracy: 0.3737 - val_loss: 4.0201\n",
            "Epoch 41/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.6990 - loss: 23.9438 - val_accuracy: 0.3643 - val_loss: 4.1088\n",
            "Epoch 42/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.7100 - loss: 23.0807 - val_accuracy: 0.3951 - val_loss: 3.6129\n",
            "Epoch 43/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 27ms/step - accuracy: 0.7209 - loss: 23.1453 - val_accuracy: 0.4179 - val_loss: 3.1274\n",
            "Epoch 44/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - accuracy: 0.7502 - loss: 19.8420 - val_accuracy: 0.4668 - val_loss: 2.7907\n",
            "Epoch 45/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.7748 - loss: 17.7015 - val_accuracy: 0.4038 - val_loss: 3.8367\n",
            "Epoch 46/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.7770 - loss: 17.5642 - val_accuracy: 0.4383 - val_loss: 3.4553\n",
            "Epoch 47/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.7849 - loss: 17.1281 - val_accuracy: 0.4631 - val_loss: 3.1682\n",
            "Epoch 48/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.8018 - loss: 15.8150 - val_accuracy: 0.4752 - val_loss: 2.9090\n",
            "Epoch 49/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.8129 - loss: 14.8647 - val_accuracy: 0.4910 - val_loss: 2.8504\n",
            "Epoch 50/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.8221 - loss: 14.1641 - val_accuracy: 0.4524 - val_loss: 3.6406\n",
            "Epoch 51/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - accuracy: 0.8309 - loss: 13.2453 - val_accuracy: 0.4997 - val_loss: 2.8970\n",
            "Epoch 52/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.8486 - loss: 12.0716 - val_accuracy: 0.5607 - val_loss: 2.2588\n",
            "Epoch 53/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.8490 - loss: 12.0293 - val_accuracy: 0.5302 - val_loss: 2.7233\n",
            "Epoch 54/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.8525 - loss: 11.4724 - val_accuracy: 0.5526 - val_loss: 2.4535\n",
            "Epoch 55/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.8677 - loss: 10.8227 - val_accuracy: 0.5868 - val_loss: 2.2036\n",
            "Epoch 56/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.8664 - loss: 10.3816 - val_accuracy: 0.5761 - val_loss: 2.3691\n",
            "Epoch 57/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.8746 - loss: 10.3249 - val_accuracy: 0.6233 - val_loss: 2.0775\n",
            "Epoch 58/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.8753 - loss: 10.0807 - val_accuracy: 0.6036 - val_loss: 2.3098\n",
            "Epoch 59/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.8839 - loss: 9.8622 - val_accuracy: 0.6324 - val_loss: 1.9839\n",
            "Epoch 60/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.8894 - loss: 9.2434 - val_accuracy: 0.5657 - val_loss: 2.6180\n",
            "Epoch 61/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 34ms/step - accuracy: 0.8928 - loss: 8.5374 - val_accuracy: 0.5885 - val_loss: 2.3407\n",
            "Epoch 62/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.9001 - loss: 8.3011 - val_accuracy: 0.6042 - val_loss: 2.3178\n",
            "Epoch 63/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.8998 - loss: 8.3211 - val_accuracy: 0.5999 - val_loss: 2.4275\n",
            "Epoch 64/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - accuracy: 0.9018 - loss: 7.9436 - val_accuracy: 0.6123 - val_loss: 2.1973\n",
            "Epoch 65/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9053 - loss: 7.6387 - val_accuracy: 0.6538 - val_loss: 1.7226\n",
            "Epoch 66/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.9096 - loss: 7.3019 - val_accuracy: 0.6307 - val_loss: 2.2334\n",
            "Epoch 67/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.9086 - loss: 7.4052 - val_accuracy: 0.6126 - val_loss: 2.3261\n",
            "Epoch 68/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.9083 - loss: 7.7621 - val_accuracy: 0.7125 - val_loss: 1.4519\n",
            "Epoch 69/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9172 - loss: 6.5397 - val_accuracy: 0.6903 - val_loss: 1.6024\n",
            "Epoch 70/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - accuracy: 0.9166 - loss: 6.6978 - val_accuracy: 0.6910 - val_loss: 1.6324\n",
            "Epoch 71/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.9206 - loss: 6.5534 - val_accuracy: 0.7081 - val_loss: 1.4884\n",
            "Epoch 72/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - accuracy: 0.9204 - loss: 6.4420 - val_accuracy: 0.6545 - val_loss: 1.8828\n",
            "Epoch 73/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9278 - loss: 6.0677 - val_accuracy: 0.7252 - val_loss: 1.3561\n",
            "Epoch 74/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9248 - loss: 6.1780 - val_accuracy: 0.7021 - val_loss: 1.5560\n",
            "Epoch 75/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9266 - loss: 6.2950 - val_accuracy: 0.7480 - val_loss: 1.1748\n",
            "Epoch 76/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9330 - loss: 5.8986 - val_accuracy: 0.7446 - val_loss: 1.1604\n",
            "Epoch 77/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.9336 - loss: 5.5073 - val_accuracy: 0.7299 - val_loss: 1.3735\n",
            "Epoch 78/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9335 - loss: 5.6912 - val_accuracy: 0.7973 - val_loss: 0.9038\n",
            "Epoch 79/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.9318 - loss: 5.8318 - val_accuracy: 0.7855 - val_loss: 1.1176\n",
            "Epoch 80/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9330 - loss: 5.9976 - val_accuracy: 0.8026 - val_loss: 0.8759\n",
            "Epoch 81/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.9316 - loss: 5.8170 - val_accuracy: 0.7329 - val_loss: 1.2610\n",
            "Epoch 82/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - accuracy: 0.9310 - loss: 5.5754 - val_accuracy: 0.7775 - val_loss: 1.1087\n",
            "Epoch 83/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.9306 - loss: 5.7408 - val_accuracy: 0.8023 - val_loss: 0.9095\n",
            "Epoch 84/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.9358 - loss: 4.8249 - val_accuracy: 0.8324 - val_loss: 0.7514\n",
            "Epoch 85/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9418 - loss: 4.8992 - val_accuracy: 0.8200 - val_loss: 0.8007\n",
            "Epoch 86/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.9471 - loss: 4.5925 - val_accuracy: 0.7768 - val_loss: 1.0126\n",
            "Epoch 87/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.9417 - loss: 4.6412 - val_accuracy: 0.8204 - val_loss: 0.7844\n",
            "Epoch 88/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9421 - loss: 4.6443 - val_accuracy: 0.8009 - val_loss: 0.8883\n",
            "Epoch 89/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9458 - loss: 4.7181 - val_accuracy: 0.8200 - val_loss: 0.7713\n",
            "Epoch 90/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9395 - loss: 5.1484 - val_accuracy: 0.8244 - val_loss: 0.7473\n",
            "Epoch 91/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.9453 - loss: 4.5442 - val_accuracy: 0.7296 - val_loss: 1.2574\n",
            "Epoch 92/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.9371 - loss: 5.3668 - val_accuracy: 0.7849 - val_loss: 0.9487\n",
            "Epoch 93/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9413 - loss: 4.9197 - val_accuracy: 0.8415 - val_loss: 0.6563\n",
            "Epoch 94/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9463 - loss: 4.0875 - val_accuracy: 0.8123 - val_loss: 0.8325\n",
            "Epoch 95/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9461 - loss: 4.3446 - val_accuracy: 0.8472 - val_loss: 0.6426\n",
            "Epoch 96/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9433 - loss: 4.3916 - val_accuracy: 0.7782 - val_loss: 1.0152\n",
            "Epoch 97/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.9404 - loss: 5.0043 - val_accuracy: 0.7808 - val_loss: 0.9537\n",
            "Epoch 98/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - accuracy: 0.9439 - loss: 4.9633 - val_accuracy: 0.8361 - val_loss: 0.7372\n",
            "Epoch 99/200\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.9434 - loss: 4.9026 - val_accuracy: 0.8505 - val_loss: 0.5927\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78e6108e8ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_dataset_output.shuffle(buffer_size=len(file_paths))\n",
        "\n",
        "# Split the dataset into train and test (80% train, 20% test)\n",
        "train_size = int(0.8 * len(file_paths))  # 80% for training\n",
        "test_size = len(file_paths) - train_size  # 20% for testing\n",
        "\n",
        "# Use `take` and `skip` to split the dataset\n",
        "train_dataset = tf_dataset.take(train_size)\n",
        "test_dataset = tf_dataset.skip(train_size)\n",
        "\n",
        "# Print the datasets\n",
        "print(f\"Train dataset: {train_size} examples\")\n",
        "print(f\"Test dataset: {test_size} examples\")\n",
        "\n",
        "# Optionally, if you want to shuffle the train and test datasets further, you can do:\n",
        "train_dataset = train_dataset.shuffle(buffer_size=train_size)\n",
        "test_dataset = test_dataset.shuffle(buffer_size=test_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UDakZEd7CLq",
        "outputId": "47221e86-d4bd-48ed-e951-25363d75b22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset: 11935 examples\n",
            "Test dataset: 2984 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# visualize the image to see what we are working with\n",
        "\n",
        "for image, label in train_dataset.take(1):\n",
        "    print(f\"Image shape: {image.shape}, Label: {label.numpy()}\")\n",
        "    plt.imshow(image.numpy())\n",
        "    plt.title(f\"Label: {label.numpy()}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "V0fECANk7Rkr",
        "outputId": "f198c85f-0513-47c5-f113-48841a702766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Attempting to slice scalar input. [Op:StridedSlice] name: strided_slice/",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-85bb0ff4a28c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Assuming the batch size is 32, take the first image from the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the first image in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the first label in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5982\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5983\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Attempting to slice scalar input. [Op:StridedSlice] name: strided_slice/"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "hg7-bMI1tV71"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h2QFCP_tQM0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "e3925b85-4a2f-4d37-9d93-8132ac15dda5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6d2a4a6e03ef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/feature_column/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDenseColumn\u001b[0m \u001b[0;31m# line: 1777\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureTransformationCache\u001b[0m \u001b[0;31m# line: 1962\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceDenseColumn\u001b[0m \u001b[0;31m# line: 1941\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfc_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_v2_types\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfc_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# =============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msquared_hinge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetric_serialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "IMG_SIZE = 128\n",
        "batch_size = 128\n",
        "\n",
        "#augmentation is used directly in model, I tried various augmentations (Contrast / Rotation) but these made most sense to me\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "#make sure all images are of same size (they should be from dataset, but to make sure)\n",
        "def resize_and_standardize(image, label):\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    image = tf.image.per_image_standardization(image) # normalization to reduce impact of contrast and brightness\n",
        "    return image, label\n",
        "\n",
        "train_dataset = (\n",
        "    train_dataset\n",
        "    .shuffle(5000) # tried higher / lower values and this seemed best\n",
        "    .map(resize_and_standardize, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "validation_dataset = (\n",
        "    validation_dataset\n",
        "    .map(resize_and_standardize, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_dataset = (\n",
        "    test_dataset\n",
        "    .map(resize_and_standardize, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "# tried simpler architectures with less Convulational layers but they could not achieve more than 70 % accuracy on 10 epochs, so I added more\n",
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        data_augmentation,\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(), # added normalization to reduce overfitting\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5), # added dropout to reduce overfitting\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n"
      ],
      "metadata": {
        "id": "wCZIpPV1GrJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam', # also tried sdg optimizer, but adam performed better\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "Bwhc9a6hraFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs_dir_path = \"/content/drive/MyDrive/CNN\""
      ],
      "metadata": {
        "id": "XNNjGZbtUNVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IrEOpXhJT7ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "tensorboard_callback = TensorBoard(\n",
        "    log_dir=logs_dir_path,\n",
        "    histogram_freq=0,\n",
        "    write_graph=True,\n",
        "    write_images=False\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qsO43dyLr0h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/CNN/horak-tomas-obraz.keras')"
      ],
      "metadata": {
        "id": "pT57PF8-r50m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
        "\n",
        "# the validation acuracy is at 82 % which is good enough for me\n"
      ],
      "metadata": {
        "id": "YJDNQCDXr9Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maZLSIFxshdv"
      },
      "source": [
        "### Displaying curves of loss and accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLhPhtphshdv",
        "outputId": "21ebb3a3-abed-456a-fe0b-233c2bef4321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# the accuracy on validation data did not drop, so there is no significant overtraining\n",
        "# the Early stopping callback correctly stopped training when the validation loss curve started to flatten"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}